{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6 Assignment: \n",
    "\n",
    "### Please type your name here:\n",
    "### Do not forget to change the filename with your name appended\n",
    "\n",
    "In this lab please fill the indicated cells with your code and explainations, ***run*** everything (select `cell` in the menu, and click `Run all`), save the notebook with your name appended to the filename (for example, `Lab-06-assignment-shuhaocao.ipynb`), and upload it to Canvas.\n",
    "<br><br>\n",
    "This lab assignment contains two problems, the first one needs to be turned, and one extra problem (for you to try after the lab session). \n",
    "<br><br>\n",
    "Read each problem carefully and answer them the best you can. You may copy the code from the Lecture 14's notebook. Even though a better way would be copy the code from Lecture 14, make the codes comment-like, type the codes by yourself using auto-completion.\n",
    "<br><br>\n",
    "For how to use a function, instead of asking others (TA, friend, your neighbor), you can put the cursor inside an empty parenthesis, press `Shift + Tab` (hold the shift key, press tab) to read the help in the pop up window, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you might find the following useful\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d # plotting surfaces\n",
    "from matplotlib.colors import LogNorm # for later use, display colormap in log scale\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero() \n",
    "# run the cell above, put the cursor inside the parenthesis and press Shift+Tab\n",
    "# you can delete this cell when turning in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function you can use to plot the convergence in contour using x_vals, y_vals\n",
    "def plot_gradient_descent(x_vals,y_vals,f):\n",
    "    X = np.linspace(-4.5,4.5,300)\n",
    "    Y = np.linspace(-4.5,4.5,300)\n",
    "    X, Y = np.meshgrid(X,Y)\n",
    "    Z = f(X, Y)\n",
    "\n",
    "    # these 4 lines of code is plotting the contour\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    CS = ax.contour(X, Y, Z, levels=np.logspace(0, 5, 35), cmap='jet', norm = LogNorm())\n",
    "    plt.axis('tight')\n",
    "    ax.clabel(CS, inline=True, fontsize=8)\n",
    "    \n",
    "    num_steps = len(x_vals)\n",
    "    delta_n = num_steps//20\n",
    "    for i in range(0,num_steps-delta_n,delta_n):\n",
    "        # plt.scatter(x_vals[i], y_vals[i])\n",
    "        plt.arrow(x_vals[i], y_vals[i], (x_vals[i+delta_n] - x_vals[i]), \n",
    "              (y_vals[i+delta_n] - y_vals[i]), \n",
    "              head_width=0.3, head_length=0.2, linewidth = 1.5, color='red')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent of Beale function\n",
    "Reference: Lecture 14 notebook\n",
    "\n",
    "In this lab we will continue to explore the gradient descent method for Beale function, which is one of the [benchmark for testing your optimization algorithm](https://en.wikipedia.org/wiki/Test_functions_for_optimization):\n",
    "$$\\displaystyle f(x,y)=\\left(1.5-x+xy\\right)^{2}+\\left(2.25-x+xy^{2}\\right)^{2} \n",
    "+\\left(2.625-x+xy^{3}\\right)^{2}$$\n",
    "We know that this function has the global minimum is achieved at $(3,0.5)$. But it has lots of traps (saddle points and local minima, very flat gradient near the global minimum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Nesterov's accelerated gradient (NAG)\n",
    "Implement the following routine, by modifying the gradient descent in Lecture 14's notebook:\n",
    "> Choose $(x_0,y_0)$, $\\eta$, $\\gamma$, and let $\\mathbf{v}_{-1} = (0,0)$ <br><br>\n",
    ">    For $k=0,1,2, \\cdots, M$<br><br>\n",
    ">    &nbsp;&nbsp;&nbsp;&nbsp;   $\\mathbf{v}_k = \\gamma \\mathbf{v}_{k-1} \n",
    "+ \\eta \\nabla f\\big( (x_k,y_k) - \\gamma \\mathbf{v}_{k-1} \\big)$<br><br>\n",
    ">    &nbsp;&nbsp;&nbsp;&nbsp;    $(x_{k+1},y_{k+1}) =  (x_k,y_k) - \\mathbf{v}_k  $\n",
    "\n",
    "This is called Nesterov's accelerated gradient by incoporating \"momentum\" and trying to extrapolating the gradient at the next iteration step.\n",
    "\n",
    "* After you define the function in the following cell, try $(x_0,y_0) = (-2,-2)$, step size $\\eta = 10^{-3}$, $\\gamma = 0.9$, and total $2000$ steps for the Beale function. Please choose $h = 10^{-6}$ in the numerical partial derivatives.\n",
    "\n",
    "* Please keep $h = 10^{-6}$ in the numerical partial derivatives, then try $(x_0,y_0) = (1,2)$, step size $\\eta = 10^{-3}$, $\\gamma = 0.8$, and total $1000$ steps for NAG on the Beale function.  Recall that in the Lab 6 practice, using the same parameter setting (without the accelarated momentum correction), the gradient descent converges not quite near the point of the minimum point $(3,0.5)$. Moreover, the vanilla gradient descent is very sensitive to the step size for Beale function. Yet, with the NAG, we should end reasonably near it with a moderately big step size (try $\\eta = 5\\cdot 10^{-3}$).\n",
    "\n",
    "HINT: you might wanna keep track the gradient at each step, and treat the $0$-th iteration different from the others.\n",
    "\n",
    "Reference: [An overview of gradient descent optimization algorithms](http://ruder.io/optimizing-gradient-descent/index.html#nesterovacceleratedgradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f  = lambda x, y: (1.5 - x + x*y)**2 + (2.25 - x + x*y**2)**2 + (2.625 - x + x*y**3)**2\n",
    "\n",
    "def numpartialx(f):\n",
    "    h = 1e-6\n",
    "    return (lambda x, y: (f(x+h, y)-f(x, y))/h)\n",
    "\n",
    "def numpartialy(f):\n",
    "    h = 1e-6\n",
    "    return (lambda x, y: (f(x, y+h)-f(x, y))/h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nesterov_acc_grad(f, x0 = (0,0), eta=1e-4, gamma = 0.9, num_steps=200):\n",
    "    # your code here\n",
    "    return x_vals, y_vals, f_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your first test here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your second test here\n",
    "num_steps = 1000\n",
    "x_vals, y_vals, f_vals = nesterov_acc_grad(f, x0 = (1,2), eta=5e-3, gamma = 0.8, num_steps = num_steps)\n",
    "print(\"The value of f(x,y): \", f_vals[-1], \"after\", \n",
    "      num_steps, \"iterations at point\", (x_vals[-1],y_vals[-1]))   \n",
    "plt.title(\"f(x,y) over gradient descent steps\")\n",
    "plt.plot(range(num_steps), f_vals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gradient_descent(x_vals,y_vals,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla GD here for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_descent(f, x0 = (0,0), eta=0.01, num_steps=200):\n",
    "    # if we do not give x0 any value, then by default it is (0,0)\n",
    "    # starting at some point\n",
    "    x, y = x0[0], x0[1]\n",
    "\n",
    "    x_vals = np.zeros(num_steps)\n",
    "    y_vals = np.zeros(num_steps)\n",
    "    f_vals = np.zeros(num_steps)\n",
    "\n",
    "    for i in range(num_steps):\n",
    "        # update x and y\n",
    "        # numerical gradient\n",
    "        dx, dy = numpartialx(f)(x,y), numpartialy(f)(x,y)\n",
    "        x = x - eta*dx\n",
    "        y = y - eta*dy\n",
    "\n",
    "        # let's store the x, y and f(x,y) values for later use\n",
    "        x_vals[i] = x\n",
    "        y_vals[i] = y\n",
    "        f_vals[i] = f(x, y)\n",
    "    \n",
    "    return x_vals, y_vals, f_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 1000\n",
    "x_vals_gd, y_vals_gd, f_vals_gd = grad_descent(f, (1,2), 1e-4, num_steps = num_steps)\n",
    "\n",
    "print(\"The value of f(x,y): \", f_vals_gd[-1], \"after\", \n",
    "      num_steps, \"iterations at point\", (x_vals_gd[-1],y_vals_gd[-1]))\n",
    "plt.plot(range(num_steps), f_vals) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gradient_descent(x_vals_gd,y_vals_gd,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Adaptive step-size/learning rate (optional)\n",
    "Another popular gradient descent algorithm in the machine learning community is [Root Mean Square Prop or RMSprop](http://ruder.io/optimizing-gradient-descent/index.html#rmsprop), which makes the step size adaptively decay according to the magnitude of the gradient. This algorithm is invented by Geoff Hinton. Despite its vast popularity in the machine learning community, it is unpublished, and it was proposed firstly in his Coursera lecture notes.\n",
    "\n",
    "RMSprop is proposed to solve two problems in the vanilla gradient descent (GD):\n",
    "* Vanishing gradient: it is observed that in Lab 6 practice even after 2000 steps, even starting somewhere like $(1,2)$ reasonably near the true global minimum point $(3,0.5)$, the GD stops or \"plateaus\" on the plateau-like region near $(3,0.5)$ (the contour looks like a plateau). It is because the gradient is too small to drive the GD forward.\n",
    "* Step-size (learning rate) has to be small to be convergent: in Lab 6, we also observe that, if starting from somewhere like $(4,4)$, a reasonably small step-size like $10^{-4}$ will make GD blow up fairly fast.\n",
    "\n",
    "The RMSprop algorithm is as follows:\n",
    "> Choose $(x_0,y_0)$, $\\eta$, $\\gamma$, $\\epsilon$, and let $s_{-1} = 1$ <br><br>\n",
    ">    For $k=0,1,2, \\cdots, M$<br><br>\n",
    ">    &nbsp;&nbsp;&nbsp;&nbsp;  $s_{k} = \\gamma s_{k-1} + (1 - \\gamma)\\, \\left|\\nabla f(x_k,y_k)\\right|^2$<br><br>\n",
    ">    &nbsp;&nbsp;&nbsp;&nbsp;    $\\displaystyle(x_{k+1},y_{k+1}) =  (x_k,y_k) -  \\frac{\\eta} {\\sqrt{s_{k}+ \\epsilon}} \\nabla f(x_k,y_k)$  \n",
    "\n",
    "Normally the parameters are chosen as: $\\gamma = 0.9$, $\\epsilon = 10^{-3}$.\n",
    "\n",
    "*  Using $h = 10^{-6}$ in the numerical partial derivatives, implement RMSprop. Try $(x_0,y_0) = (1,2)$, step size $\\eta = 10^{-2}$, $\\gamma = 0.9$, $\\epsilon = 10^{-3}$, and total $1000$ steps for RMSprop on the Beale function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsprop_grad(f, x0 = (0,0), eta=1e-1, gamma = 0.9, eps = 1e-3, num_steps=200):\n",
    "    # your code here\n",
    "    return x_vals, y_vals, f_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your test here\n",
    "num_steps = 1000\n",
    "x_vals, y_vals, f_vals = rmsprop_grad(f, x0 = (1,2), eta=1e-2, gamma = 0.9, num_steps = num_steps)\n",
    "print(\"The value of f(x,y): \", f(x_vals[-1],y_vals[-1]), \"after\", \n",
    "      num_steps, \"iterations at point\", (x_vals[-1],y_vals[-1]))\n",
    "plt.title(\"f(x,y) over gradient descent steps\")\n",
    "plt.plot(range(num_steps), f_vals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_gradient_descent(x_vals,y_vals,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Lab 6 done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A hard extra problem \n",
    "## (come find your instructor for extra credit if you have done this by modifying the sample code in Lecture 14)\n",
    "Try to combine RMSprop and NAG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading: how to determine step-size\n",
    "A starter would include the wikipedia entries for [Line search](https://en.wikipedia.org/wiki/Line_search) and [backtrack line search](https://en.wikipedia.org/wiki/Backtracking_line_search).\n",
    "\n",
    "Advanced: [UCLA's CS289's notes on gradient descent method](https://raghumeka.github.io/CS289ML/gdnotes.pdf), essentially we are considering the gradient itself as a Lipschitz function."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
