{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Practice Week 9\n",
    "\n",
    "This notebook does not need to be submitted. This lab will prepare you for the final project and the final exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as always\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Problem 1\n",
    "\n",
    "In this problem, we will learn how the `sort`, `argsort`, and `unique` functions work, all of which are among the key components in building Bayesian-related machine learning model, including the naive Bayes (kNN), the parameters of the models are obtained through Bayesian inference instead of gradient descent, and optimization-based model like softmax regression.\n",
    "\n",
    "\n",
    "### How exactly is kNN implementation (for loops) working in action\n",
    "\n",
    "The code snippets below are illustrating how the to retrieve the points and indices for distances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Given the following array that has 10 entries, each of which represents a distance a given testing sample is to 11 other training samples, such that `dist[i]` represent the distance of this sample to the $(i+1)$-th training sample: \n",
    "```python\n",
    "dist = np.array([0.35008417,  0.78681104,  1.07813751,  0.46923679,  0.11855759,\n",
    "          0.67652192,  0.02188573,  1.20928837,  0.29410932,  0.07701728, 0.94784323])\n",
    "```\n",
    "For example, this given sample has `0.35008417` distance to the first training sample.\n",
    "\n",
    "* Read the [reference of `sort`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.sort.html), and use `sort` to find the closest distance among these 11 training samples to this given testing sample.\n",
    "* Read the [reference of `argsort`](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.argsort.html), use `argsort` to find the index of the closest training sample that is to this testing sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 (continued)\n",
    "Given the following array that contains the classes of 11 nearest neighbors of the given testing sample using the `dist` array above:\n",
    "```python\n",
    "nearest_neighbor_classes = np.array([2, 5, 6, 5, 2, 2, 3, 0, 1, 0, 2])\n",
    "```\n",
    "For example, the nearest neighbor to the given testing sample is of class 2, and according to the distance array `dist`, the distance of this testing sample to its nearest neighbor is `0.02188573`. \n",
    "\n",
    "* Read the [reference of `unique`](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.unique.html), use `unique` to find the class in which this given sample has the first, and second most neighbors among these 11 neighbors. You might want to set the option `return_counts = True`.\n",
    "* We can use the following code to find the inverse of the distance array `dist_inv` (where `dist_inv[i] = 1/dist[i]`) that is of class 3:\n",
    "```python\n",
    "dist_inv[nearest_neighbor_classes == 3]\n",
    "```\n",
    "The nonzero entries of the array above are the inverse distances to this testing sample from the 11 neighbors which are of class 3. \n",
    "Find the class of which this inverse distance sum is the greatest among classes 0 to 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: $k$-NN on MNIST\n",
    "\n",
    "\n",
    "Download the MNIST dataset as zip file either from Canvas or [from Kaggle](https://www.kaggle.com/oddrationale/mnist-in-csv), unzip it and put the csv file in the same folder with this notebook. Please use the `loadtxt` function from numpy to import the file, and extract 0s and 1s from the MNIST dataset (Reference: Lecture 18).\n",
    "\n",
    "Alternatively, download the `npz` files of MNIST binary dataset (only 0s and 1s) from Canvas files tab (Reference: Lecture 19).\n",
    "\n",
    "If you have done so, please complete the following task.\n",
    "* Import the `KNeighborsClassifier` class from `sklearn.neighbors` submodule, and apply `KNeighborsClassifier` on the binary MNIST dataset. Follow the train->test routine in Lecture 21's notebook.\n",
    "* Read the usage of the $kD$-tree in the [`KNeighborsClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html), and let the `algorithm` option to be `kd_tree` in `KNeighborsClassifier`, change the `leaf_size` option from 30 (default), to 100 and 400, measure the time needed for the algorithm to run. To measure the processing time of a routine, please refer to the cell below.\n",
    "\n",
    "#### Reference: \n",
    "* [https://scikit-learn.org/stable/modules/neighbors.html](https://scikit-learn.org/stable/modules/neighbors.html)\n",
    "* [Notes on Algorithms for Finding Nearest Neighbors (and Relatives) by Piotr Indyk](https://people.csail.mit.edu/indyk/helsinki-1.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure the processing time\n",
    "import time\n",
    "arr = np.arange(10000)\n",
    "starting_time = time.process_time()\n",
    "for i in range(10000):\n",
    "    arr[i] *= arr[i]\n",
    "print(\"Element-wise squaring using for loop takes \", time.process_time() - starting_time)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
