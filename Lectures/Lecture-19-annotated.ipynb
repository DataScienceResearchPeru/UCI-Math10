{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 19: Softmax regression, multiclass classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last lecture we have learned the logistic regression to classify \"0\" digit or a \"1\" digit based on pixel intensities on a 28x28 grid.\n",
    "\n",
    "Today we will learn how to classify all 10 digits.\n",
    "\n",
    "Reference: adapted from the MATLAB tutorial in [Stanford Deep Learning tutorial](http://deeplearning.stanford.edu/tutorial/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST\n",
    "Let us load the [MNIST dataset of handwritten digits](http://yann.lecun.com/exdb/mnist/), both testing and training data. You can download the `npz` format file on Canvas file tab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does the data look like?\n",
    "* (If you use the same routine with Lecture 18 to load the `csv` data) The first column of `data_train[:,0]` and `data_test[:,0]` are the labels, and the rest 784 columns `data_train[:,1:]` and `data_test[:,1:]`represent a 28x28 grayscale image. \n",
    "* If you have loaded the `npz` data (numpy native format), `X_train` and `X_test` both have 784 columns which represent a 28x28 grayscale image. `y_train` and `y_test`, which range from 0 to 9 total 10 classes, are the labels of the training samples, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = np.load('mnist_train.npz')\n",
    "X_train = data_train['X']\n",
    "y_train = data_train['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.lib.npyio.NpzFile"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X', 'y']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "# 784 = 28 x 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 0., 4.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = np.load('mnist_test.npz')\n",
    "X_test = data_test['X']\n",
    "y_test = data_test['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the first 20 rows of the training data, with their labels.\n",
    "_, axes = plt.subplots(4,5, figsize=(16, 10))\n",
    "\n",
    "axes = axes.reshape(-1)\n",
    "\n",
    "for i in range(20):\n",
    "    axes[i].axis('off') # hide the axes ticks\n",
    "    axes[i].imshow(X_train[i,:].reshape(28,28), cmap = 'gray')\n",
    "    axes[i].set_title(str(int(y_train[i])), color= 'black', fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax regression (reading)\n",
    "<br>\n",
    "Softmax regression (or multinomial logistic regression) is a generalization of logistic regression to the case where we want to handle multiple classes. In logistic regression we assumed that the labels were binary: $y^{(i)}∈{0,1}$. In the last lecture, we have used such a classifier to distinguish between two kinds of handwritten digits. Softmax regression allows us to handle $y^{(i)}\\in \\{1,\\dots, K\\}$ where $K$ is the number of classes.\n",
    "\n",
    "Given a test input $\\mathbf{x}\\in \\mathbb{R}^n$ (a 28x28 image flattened to a `(784,)` array), we want to estimate the probability that $P(y=k|\\mathbf{x})$ for each value of $k=1,\\dots,K$. In other words, from the input image, we want to estimate the probability of this image being classified as each label among $K$ labels, and we choose the highest probable one to label this image. Thus, our model (hypothesis) will output a $K$-dimensional vector (whose elements sum to $1$ to make it a probability) giving us our $K$ estimated probabilities. Concretely, our model $h(\\mathbf{x}; \\mathbf{w})$, which stands for given the current weights $\\mathbf{w}$ the probability vector for $\\mathbf{x}$, takes the form:\n",
    "\n",
    "$$\n",
    "h_{\\mathbf{w}}(\\mathbf{x}) =\n",
    "\\begin{pmatrix}\n",
    "P(y = 1 | \\mathbf{x}; \\mathbf{w}) \\\\\n",
    "P(y = 2 | \\mathbf{x}; \\mathbf{w}) \\\\\n",
    "\\vdots \\\\\n",
    "P(y = K | \\mathbf{x}; \\mathbf{w})\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\frac{1}{ \\sum_{j=1}^{K}{\\exp\\big(\\mathbf{w}_j^{\\top} \\mathbf{x}\\big) }}\n",
    "\\begin{pmatrix}\n",
    "\\exp(\\mathbf{w}_1^{\\top} \\mathbf{x} ) \\\\\n",
    "\\exp(\\mathbf{w}_2^{\\top} \\mathbf{x} ) \\\\\n",
    "\\vdots \\\\\n",
    "\\exp(\\mathbf{w}_K^{\\top} \\mathbf{x} ) \\\\\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "Totally we have $K$ sets of parameters, $\\mathbf{w}_1, \\mathbf{w}_2, \\dots, \\mathbf{w}_K$, and the factor $\\sum_{j=1}^{K}{\\exp\\big(\\mathbf{w}_j^{\\top} \\mathbf{x}\\big)}$ normalizes the results to be a probability.\n",
    "\n",
    "When we implement the softmax regression, it is usually convenient to represent $\\mathbf{w}$ containing all $K$ sets of parameters as a $n\\times K$ matrix obtained by concatenating $\\mathbf{w}_1, \\mathbf{w}_2, \\dots, \\mathbf{w}_K$ into columns, so that $\\mathbf{w}_k = (w_{k1}, \\dots, w_{kn})^{\\top} = (w_{kl})$ for $l = 1,\\dots, n$\n",
    "\n",
    "$$\n",
    "\\mathbf{w} = \\left(\n",
    "\\begin{array}{cccc}| & | & | & | \\\\\n",
    "\\mathbf{w}_1 & \\mathbf{w}_2 & \\cdots & \\mathbf{w}_K \\\\\n",
    "| & | & | & |\n",
    "\\end{array}\\right),\n",
    "$$\n",
    "and $\\mathbf{w}^{\\top}\\mathbf{x}$ would be sensible and vectorized to be computed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function\n",
    "Before introducting the loss the function for the softmax regression, we define the following indicator function:\n",
    "$$\n",
    "1_{\\{y = k\\}} = 1_{\\{k\\}}(y) = \\delta_{yk} = \\begin{cases}\n",
    "1 & \\text{when } y = k,\n",
    "\\\\[5pt]\n",
    "0 & \\text{otherwise}.\n",
    "\\end{cases}\n",
    "$$\n",
    "First let us recall the loss function for the logistic regression, and we rewrite it as: we have $N$ training samples $(\\mathbf{x}^{(i)}, y^{(i)})$\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\ell^{\\text{Logistic}} (\\mathbf{w}) &= - \\sum_{i=1}^N \n",
    "\\Bigl\\{y^{(i)} \\ln\\big( h(\\mathbf{x}^{(i)}) \\big) \n",
    "+ (1 - y^{(i)}) \\ln\\big( 1 - h(\\mathbf{x}^{(i)}) \\big) \\Bigr\\}\n",
    "\\\\\n",
    "& = - \\sum_{i=1}^N \\sum_{k=0}^1\n",
    "\\Bigl\\{ 1_{\\{y^{(i)} = k\\}} \\ln P\\big(y^{(i)}=k | \\mathbf{x}^{(i)} ; \\mathbf{w} \\big) \\Bigr\\}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Now our loss function for the softmax regression is then the generalization of above:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L (\\mathbf{w}) = L^{\\text{Softmax}} (\\mathbf{w}) & = - \\sum_{i=1}^N \\sum_{k=1}^K\n",
    "\\Bigl\\{ 1_{\\{y^{(i)} = k\\}} \\ln P\\big(y^{(i)}=k | \\mathbf{x}^{(i)} ; \\mathbf{w} \\big) \\Bigr\\}\n",
    "\\\\\n",
    " & = - \\sum_{i=1}^N \\sum_{k=1}^K\n",
    "\\left\\{1_{\\{y^{(i)} = k\\}} \\ln \\Bigg( \\frac{\\exp(\\mathbf{w}_k^{\\top} \\mathbf{x}^{(i)})}{\\sum_{j=1}^{K} \n",
    "\\exp\\big(\\mathbf{w}_j^{\\top} \\mathbf{x}^{(i)} \\big) }  \\Bigg)\\right\\}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "Notice for every term in the sum w.r.t. to the labels, $\\sum_{k=1}^K$, $1_{\\{y^{(i)} = k\\}} = 1$ for only one term among $K$ terms, and the rest is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient of softmax loss function \n",
    "# (you might want to  re-derive this on paper)\n",
    "\n",
    "Notice our weights to be trained have $K$ sets $\\mathbf{w}_1, \\mathbf{w}_2, \\dots, \\mathbf{w}_K$, and each of the $k$-th weights vector has $n$ components: $\\mathbf{w}_k = (w_{k1}, \\dots, w_{kl},\\dots, w_{kn})^{\\top}$. The first subscript is $1\\leq k \\leq K$ (label's index, we have this many set of weights), the second subscript is $1\\leq l\\leq n$ ($\\mathbf{x}$'s feature index). \n",
    "\n",
    "The indices involved are pretty complicated, to simplify the notation a bit, denote the probability predicted by our model of the $i$-th training sample being in the $k$-th class as:\n",
    "\n",
    "$$\n",
    "\\sigma_{k}^{(i)}:= P\\big(y^{(i)}=k | \\mathbf{x}^{(i)} ; \\mathbf{w} \\big) = \n",
    "\\frac{\\exp(\\mathbf{w}_k^{\\top} \\mathbf{x}^{(i)})} {\\sum_{m=1}^{K} \n",
    "\\exp(\\mathbf{w}_m^{\\top} \\mathbf{x}^{(i)} )}\n",
    "$$\n",
    "then \n",
    "$$\n",
    "\\frac{\\partial L }{\\partial w_{jl}}\n",
    "= - \\sum_{i=1}^N \\sum_{k=1}^K \n",
    "\\left\\{ 1_{\\{y^{(i)} = k\\} } \\frac{\\partial}{\\partial w_{jl}}\\Big( \\ln \\sigma_{k}^{(i)}\\Big)\n",
    "\\right\\}\n",
    "= - \\sum_{i=1}^N \\sum_{k=1}^K \n",
    "\\left\\{ 1_{\\{y^{(i)} = k\\} } \\frac{1}{\\sigma_{k}^{(i)}}\\frac{\\partial}{\\partial w_{jl}} \\sigma_{k}^{(i)}\n",
    "\\right\\}.\n",
    "\\tag{$\\star$}\n",
    "$$\n",
    "\n",
    "Now computing the partial derivative above:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial \\sigma_{k}^{(i)}}{\\partial w_{jl}} \n",
    "&= \n",
    "\\frac{\\partial }{\\partial w_{jl}} \\left( \\frac{\\exp(\\mathbf{w}_k^{\\top} \\mathbf{x}^{(i)})} {\\sum_{m=1}^{K} \n",
    "\\exp(\\mathbf{w}_m^{\\top} \\mathbf{x}^{(i)} )}\\right)\n",
    "\\\\\n",
    "&= \\frac{1}{\\sum_{m=1}^{K}\\exp(\\mathbf{w}_m^{\\top} \\mathbf{x}^{(i)} )}\n",
    "\\frac{\\partial }{\\partial w_{jl}} \\left(  \\exp(\\mathbf{w}_k^{\\top} \\mathbf{x}^{(i)})\\right)\n",
    "- \\frac{\\exp(\\mathbf{w}_k^{\\top} \\mathbf{x}^{(i)})}\n",
    "{ \\left(\\sum_{m=1}^{K}\\exp(\\mathbf{w}_m^{\\top} \\mathbf{x}^{(i)}) \\right)^2}\n",
    "\\frac{\\partial }{\\partial w_{jl}} \\left(  \\sum_{m=1}^{K}\\exp(\\mathbf{w}_m^{\\top} \\mathbf{x}^{(i)})  \\right)\n",
    "\\\\\n",
    "&= \\frac{1}{\\sum_{m=1}^{K}\\exp(\\mathbf{w}_m^{\\top} \\mathbf{x}^{(i)} )}\n",
    "1_{\\{j = k\\}} \\exp(\\mathbf{w}_k^{\\top} \\mathbf{x}^{(i)})\n",
    "\\frac{\\partial }{\\partial w_{jl}} \\left( \\mathbf{w}_k^{\\top} \\mathbf{x}^{(i)} \\right)\n",
    "- \\frac{\\exp(\\mathbf{w}_k^{\\top} \\mathbf{x}^{(i)})}\n",
    "{ \\left(\\sum_{m=1}^{K}\\exp(\\mathbf{w}_m^{\\top} \\mathbf{x}^{(i)}) \\right)^2}\n",
    "\\exp(\\mathbf{w}_j^{\\top} \\mathbf{x}^{(i)})\n",
    "\\frac{\\partial }{\\partial w_{jl}} \\left( \\mathbf{w}_j^{\\top} \\mathbf{x}^{(i)} \\right).\n",
    "\\end{aligned}\n",
    "\\tag{$\\dagger$}\n",
    "$$\n",
    "\n",
    "By the property of the indicator function, we have:\n",
    "\n",
    "$$\n",
    "1_{\\{j = k\\}} \\exp(\\mathbf{w}_k^{\\top} \\mathbf{x}^{(i)})\n",
    "\\frac{\\partial }{\\partial w_{jl}} \\left( \\mathbf{w}_k^{\\top} \\mathbf{x}^{(i)} \\right)\n",
    "= \\begin{cases}\n",
    "\\exp(\\mathbf{w}_j^{\\top} \\mathbf{x}^{(i)}) x_l^{(i)} & \\text{if } j=k,\n",
    "\\\\[3pt]\n",
    "0 & \\text{if }j\\neq k.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Hence, $(\\dagger)$ can be further written as:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial \\sigma_{k}^{(i)}}{\\partial w_{jl}}  \n",
    "= \\frac{\\exp(\\mathbf{w}_k^{\\top} \\mathbf{x}^{(i)})}\n",
    "{ \\sum_{m=1}^{K}\\exp(\\mathbf{w}_m^{\\top} \\mathbf{x}^{(i)}) }\n",
    "\\left(\n",
    "1_{\\{j = k\\}} - \n",
    " \\frac{\\exp(\\mathbf{w}_j^{\\top} \\mathbf{x}^{(i)})}\n",
    "{ \\sum_{m=1}^{K}\\exp(\\mathbf{w}_m^{\\top} \\mathbf{x}^{(i)}) }\n",
    "\\right) x^{(i)}_l\n",
    "= \\sigma_{k}^{(i)} \\left(\n",
    "1_{\\{j = k\\}} - \\sigma_{j}^{(i)} \\right) x^{(i)}_l.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Now plugging this back to $(\\star)$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial L }{\\partial w_{jl}}\n",
    "&= - \\sum_{i=1}^N \\sum_{k=1}^K \n",
    "\\left\\{ 1_{\\{y^{(i)} = k\\} } \n",
    "\\left(\n",
    "1_{\\{j = k\\}} - \\sigma_{j}^{(i)} \\right) x^{(i)}_l\n",
    "\\right\\}\n",
    "\\\\\n",
    "&=- \\sum_{i=1}^N \n",
    "x^{(i)}_l\\left\\{ \\sum_{k=1}^K  \n",
    "1_{\\{y^{(i)} = k\\} } 1_{\\{j = k\\}} - \n",
    "\\sum_{k=1}^K 1_{\\{y^{(i)} = k\\} } \\sigma_{j}^{(i)}  \n",
    "\\right\\}\n",
    "\\\\\n",
    "&=\n",
    "- \\sum_{i=1}^N \n",
    "x^{(i)}_l\\left(   \n",
    "1_{\\{y^{(i)} = j\\} } -  \\sigma_{j}^{(i)}  \n",
    "\\right)\n",
    "\\\\\n",
    "& = \n",
    "- \\sum_{i=1}^N \n",
    "x^{(i)}_l\\Big(   \n",
    "1_{\\{y^{(i)} = j\\} } -  P\\big(y^{(i)}=j | \\mathbf{x}^{(i)} ; \\mathbf{w} \\big)  \n",
    "\\Big).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "This is pretty simple, and it has a nice interpretation similar to the maximum likelihood function: the term in the parenthesis is the difference between the actual probability and the probability estimation in our model.\n",
    "\n",
    "Now the derivative of $L$ with respect the whole $j$-th set of weights is then:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L }{\\partial \\mathbf{w}_{j}}\n",
    "= - \\sum_{i=1}^N \n",
    "\\mathbf{x}^{(i)}\\left(   1_{\\{y^{(i)} = j\\} } -  \\sigma_{j}^{(i)}  \n",
    "\\right)\n",
    "=\n",
    "\\sum_{i=1}^N \n",
    "\\mathbf{x}^{(i)}\\left(    \\frac{\\exp(\\mathbf{w}_j^{\\top} \\mathbf{x}^{(i)})} {\\sum_{m=1}^{K} \n",
    "\\exp(\\mathbf{w}_m^{\\top} \\mathbf{x}^{(i)} )} -1_{\\{y^{(i)} = j\\} } \n",
    "\\right).\n",
    "\\tag{$\\diamond$}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent\n",
    "Now let us implement the gradient descent based on $(\\diamond)$ above, with code adapted from Lecture 18. One big challenge here is that the weights are now represented by a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global training data\n",
    "X = X_train\n",
    "y = y_train\n",
    "N = len(y) # number of training samples\n",
    "n = np.shape(X)[1] # 784, which is number of pixels (number of features)\n",
    "K = 10 # number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(666)\n",
    "w  = 1e-4*np.random.random(n*K) \n",
    "# w: a (7840, ) array a small, random initial guess\n",
    "# 7840 = 784x10, 784 features, 10 classes\n",
    "# during computation it will be resized to total 10 columns standing for 10 sets of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.00437122e-05, 8.44186643e-05],\n",
       "       [2.00247539e-05, 7.44154169e-05],\n",
       "       [2.32362992e-06, 7.27321154e-05],\n",
       "       ...,\n",
       "       [2.96672070e-05, 4.70666347e-05],\n",
       "       [4.54639959e-05, 8.55445610e-07],\n",
       "       [8.88722408e-05, 1.36122991e-05]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weights for first two classes\n",
    "w.reshape(n,K)[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.5548548 , 3.99514731, 4.05174346, 3.76647625, 4.03539205,\n",
       "        3.74817156, 3.56257827, 4.01870986, 3.62638062, 4.23358375],\n",
       "       [4.71179996, 4.8744543 , 4.64823956, 4.49079842, 4.86802489,\n",
       "        4.65967716, 4.63921643, 4.86412303, 4.70220507, 5.01239012]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the following single line computes e^(weights dot product with samples) \n",
    "# for each set of weights (K sets of weights for K classes)\n",
    "# and for each data samples\n",
    "# s is of shape (60000, 10)\n",
    "s = np.exp(np.matmul(X,w.reshape(n,K)))\n",
    "s[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([38.59303791, 47.47092896])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computes the sum along axis = 1, summing up all columns for each row\n",
    "np.apply_along_axis(np.sum, axis=1, arr= s)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0921113 , 0.1035199 , 0.10498638, 0.09759471, 0.10456269,\n",
       "        0.09712041, 0.09231142, 0.10413044, 0.09396463, 0.10969812],\n",
       "       [0.09925654, 0.10268293, 0.0979176 , 0.09460102, 0.1025475 ,\n",
       "        0.09815854, 0.09772753, 0.1024653 , 0.09905441, 0.10558863]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each row is normalized by its sum so that we get a probability (each number between 0 and 1, summing up to 1)\n",
    "prob = s / np.apply_along_axis(np.sum, axis=1, arr= s).reshape(-1,1)\n",
    "prob[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model sigma(x; w) \n",
    "# w: 10 sets weights\n",
    "# X: training samples, of shape 60000 row by 784\n",
    "# output: (60000, 10), i-th row represent the probabilities of i-th sample\n",
    "# in the k-th class (k-th column entry)\n",
    "def sigma(w,X):\n",
    "    w = w.reshape(n,K)\n",
    "    s = np.exp(np.matmul(X,w))\n",
    "    total = np.apply_along_axis(np.sum, axis=1, arr=s).reshape(-1,1)\n",
    "    prob = s / total\n",
    "    return prob\n",
    "\n",
    "# loss function, modulo by N (size of training data)\n",
    "# a vectorized implementation with a for loop with only 10 iterations\n",
    "def loss(w,X,y):\n",
    "    loss_components = np.zeros(N)\n",
    "    for k in range(K):\n",
    "        loss_components += np.log(sigma(w,X))[:,k] * (y == k)\n",
    "    # above is a dimension (60000,) array\n",
    "    return -np.mean(loss_components) # same with loss_components.sum()/N\n",
    "\n",
    "def gradient_loss(w,X,y):\n",
    "    gradient_for_each_weight_class = np.empty([n,K]) \n",
    "    # 10 columns, each column represent a graident\n",
    "    for k in range(K):\n",
    "        gradient_for_all_training_data_for_class_k = (sigma(w,X)[:,k] - (y==k)).reshape(-1,1)*X\n",
    "        gradient_for_each_weight_class[:,k] = np.mean(gradient_for_all_training_data_for_class_k, axis=0)\n",
    "    # we should return a (784,) array, which is averaging all 60000 training data\n",
    "    return gradient_for_each_weight_class.reshape(n*K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_for_each_weight_class = np.empty([n,K]) # same shape with reshaped w\n",
    "for k in range(10):\n",
    "    gradient_for_all_training_data_for_class_k = (sigma(w,X)[:,k] - (y==k)).reshape(-1,1)*X\n",
    "    gradient_for_each_weight_class[:,k] = np.mean(gradient_for_all_training_data_for_class_k, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label_residual is the (probability of sample x in class k predicted by our model) - (indicator function of x is in class k or not)\n",
    "label_residual = (sigma(w,X)[:,k] - (y==k)).reshape(-1,1)\n",
    "# label_residual*X is the key term in the gradient of softmax loss function\n",
    "# gradient_for_kth_class_weight is the gradient of the weights responsible for the k-th class\n",
    "gradient_for_kth_class_weight = np.mean(label_residual*X, axis = 0)\n",
    "gradient_for_kth_class_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9814247301745523"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(w,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199.3463223447666"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(gradient_loss(w,X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation function\n",
    "For a fixed set of weights `sigma(w)` gives 10 probabilities for each sample (training or testing), here we want to implement a cross-validation function, takes input of `X_train` or `X_test`, compute the class label of the highest probability for each samples, and returns the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define a cross validating function computing \n",
    "def cross_validate_acc(w,X,y):\n",
    "    prob = sigma(w,X) # for each sample, it computes 10 probabilities based on current weight w\n",
    "    highest_prob_index = np.argmax(prob, axis=1)\n",
    "    return np.mean(highest_prob_index == y.astype(int))\n",
    "    # same with (highest_prob_index == y.astype(int)).sum()/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0921113 , 0.1035199 , 0.10498638, 0.09759471, 0.10456269,\n",
       "        0.09712041, 0.09231142, 0.10413044, 0.09396463, 0.10969812],\n",
       "       [0.09925654, 0.10268293, 0.0979176 , 0.09460102, 0.1025475 ,\n",
       "        0.09815854, 0.09772753, 0.1024653 , 0.09905441, 0.10558863],\n",
       "       [0.09327886, 0.1024089 , 0.10386954, 0.09664264, 0.10512896,\n",
       "        0.09983215, 0.10147139, 0.10390017, 0.09314344, 0.10032396]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = sigma(w,X)\n",
    "prob[:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 9, 4], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(prob, axis=1)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after 1 iterations is:  1.7220303275646196\n",
      "Training accuracy after 1 iterations is:  0.7476833333333334\n",
      "Testing accuracy after 1 iterations is:  0.7578\n",
      "loss after 2 iterations is:  1.3957194175114263\n",
      "Training accuracy after 2 iterations is:  0.7187833333333333\n",
      "Testing accuracy after 2 iterations is:  0.7268\n",
      "loss after 3 iterations is:  1.2021446377303109\n",
      "Training accuracy after 3 iterations is:  0.74845\n",
      "Testing accuracy after 3 iterations is:  0.7547\n",
      "loss after 4 iterations is:  1.1114388752685722\n",
      "Training accuracy after 4 iterations is:  0.7353166666666666\n",
      "Testing accuracy after 4 iterations is:  0.7411\n",
      "loss after 5 iterations is:  1.0000586103254194\n",
      "Training accuracy after 5 iterations is:  0.7632\n",
      "Testing accuracy after 5 iterations is:  0.7721\n"
     ]
    }
   ],
   "source": [
    "eta = 1e-5  # step size (learning rate)\n",
    "num_steps = 5\n",
    "\n",
    "loss_at_eachstep = np.zeros(num_steps) # record the change of the loss function\n",
    "for i in range(num_steps):\n",
    "    loss_at_eachstep[i] = loss(w,X,y)\n",
    "    dw = gradient_loss(w,X,y)\n",
    "    w = w - eta * dw\n",
    "    print(\"loss after\", i+1, \"iterations is: \", loss_at_eachstep[i])\n",
    "    print(\"Training accuracy after\", i+1, \"iterations is: \", cross_validate_acc(w,X,y))\n",
    "    print(\"Testing accuracy after\", i+1, \"iterations is: \", cross_validate_acc(w,X_test,y_test))\n",
    "    # keep track of training accuracy just making sure we are in the right direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slow, slow, slow\n",
    "Because our dataset is big. One iteration of the gradient descent requires evaluating the gradient for all the training samples, and it takes takes $O(N\\cdot d)$ cpu time ($N$: number of training samples, $d$:number of features in each sample). Stochastic gradient descent to remedy next time..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Always scikit-learn to rescue\n",
    "\n",
    "We can use `scikit-learn`'s [`LogisticRegression()` class](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) in the `linear_model` to perform this task for us. Quoting the reference:\n",
    "> In the multiclass case, the training algorithm uses the one-vs-rest (OvR) scheme if the 'multi_class' option is set to 'ovr', and uses the cross- entropy loss if the 'multi_class' option is set to 'multinomial'. (Currently the 'multinomial' option is supported only by the 'lbfgs', 'sag' and 'newton-cg' solvers.)\n",
    "\n",
    "> For small datasets, 'liblinear' is a good choice, whereas 'sag' and 'saga' are faster for large ones.\n",
    "For multiclass problems, only 'newton-cg', 'sag', 'saga' and 'lbfgs' handle multinomial loss; 'liblinear' is limited to one-versus-rest schemes.\n",
    "'newton-cg', 'lbfgs' and 'sag' only handle L2 penalty, whereas 'liblinear' and 'saga' handle L1 penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the example\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "mnist_clf = LogisticRegression(random_state=666, \n",
    "                               solver='lbfgs', tol= 1e-5, max_iter = 2000, verbose=True, \n",
    "                               multi_class='multinomial')\n",
    "# a faster solver is sag according to the reference\n",
    "# verbose is printing output during training (only applies to lbfgs as solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:719: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   30.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=2000, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=666, solver='lbfgs',\n",
       "          tol=1e-05, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_clf.fit(X_train[:10000,:], y_train[:10000]) # we only use first 10000 images as training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7., 2., 1., 0., 4., 1., 4., 9., 6., 7.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_clf.predict(X_test[:10, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we visualize the first 10 rows of X_test, see how the prediction goes\n",
    "# visualize the first 20 rows of the training data, with their labels.\n",
    "_, axes = plt.subplots(2,5, figsize=(16, 5))\n",
    "axes = axes.reshape(-1)\n",
    "\n",
    "for i in range(10):\n",
    "    axes[i].axis('off') # hide the axes ticks\n",
    "    axes[i].imshow(X_test[i,:].reshape(28,28), cmap = 'gray')\n",
    "    axes[i].set_title(str(int(y_test[i])), color= 'black', fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "Our softmax got 8 out 10 correct, not a bad score. Run the following cell will give you the prediction accuracy for the first 500 testing samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.862"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_clf.score(X_test[:500,:], y_test[:500])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
